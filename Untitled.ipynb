{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Neural Net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NOTE: Need to create my own data loader\n",
    "\n",
    "# The number of pixels in each dimension of an image.\n",
    "img_size = 28#data.img_size\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = 784 #data.img_size_flat\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (28,28)#data.img_shape\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10 #data.num_classes\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1 #data.num_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Conv Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input,\n",
    "                   num_input_channels,\n",
    "                   filter_size,\n",
    "                   num_filters,\n",
    "                   use_pooling=True):\n",
    "    \n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    \n",
    "    weights = new_weights(shape)\n",
    "    \n",
    "    biases = new_biases(num_filters)\n",
    "    \n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter= weights,\n",
    "                         strides=[1,1,1,1],\n",
    "                         padding=\"SAME\")\n",
    "    layer += biases\n",
    "    \n",
    "    if use_pooling:\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1,2,2,1],\n",
    "                               strides=[1,2,2,1],\n",
    "                               padding=\"SAME\")\n",
    "    \n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(inputs,\n",
    "                 num_inputs,\n",
    "                 num_outputs,\n",
    "                 use_relu=True):\n",
    "    \n",
    "    weights = new_weights([num_inputs, num_outputs])\n",
    "    biases = new_biases(length= num_outputs)\n",
    "    \n",
    "    layer = tf.matmul(inputs, weights) + biases\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "        \n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place holder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_size_flat], name=\"x\")\n",
    "\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, [None, num_classes], name=\"y_true\")\n",
    "\n",
    "y_labels = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "layer_conv1, weights_1 = new_conv_layer(input=x_image,\n",
    "                                      num_input_channels=num_channels,\n",
    "                                      filter_size = filter_size1,\n",
    "                                      num_filters = num_filters1,\n",
    "                                      use_pooling= True)\n",
    "    \n",
    "layer_conv2, weights_2 = new_conv_layer(input=layer_conv1,\n",
    "                                      num_input_channels=num_filters1,\n",
    "                                      filter_size = filter_size2,\n",
    "                                      num_filters = num_filters2,\n",
    "                                      use_pooling= True)\n",
    "\n",
    "flat_layer, num_features = flatten_layer(layer_conv2)\n",
    "\n",
    "\n",
    "fc1 = new_fc_layer(flat_layer, \n",
    "                     num_features,\n",
    "                     num_outputs=fc_size,)\n",
    "\n",
    "fc2_logits = new_fc_layer(fc1,\n",
    "                  num_inputs=fc_size,\n",
    "                  num_outputs=num_classes,\n",
    "                  use_relu=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get test accuarcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = tf.nn.softmax(fc2_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_class = tf.argmax(y_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=fc2_logits, labels=y_true)\n",
    "loss = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = tf.equal(y_preds_class, y_labels)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    global total_iterations\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    data = Data('data/train.csv')\n",
    "    \n",
    "    # trainin loop\n",
    "    \n",
    "    for i in range(total_iterations, total_iterations + epochs):\n",
    "        \n",
    "        x_batch, y_true_batch = data.random_batch(bs=bs, epoch=i)\n",
    "        \n",
    "#         print(x_batch)\n",
    "        \n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        \n",
    "        session.run(optim, feed_dict= feed_dict_train)\n",
    "        \n",
    "        acc = session.run(accuracy,feed_dict= feed_dict_train)\n",
    "        \n",
    "    print(acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    " data = Data('data/train.csv')\n",
    "x_batch, y_true_batch = data.random_batch(bs=bs, epoch=2, is_test=True)\n",
    "feed_dict_test = {x: x_batch, y_true: y_true_batch}\n",
    "acc = session.run(y_preds,feed_dict=feed_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 6, 5, 7, 3, 7, 3, 6, 5, 3, 8, 5, 9, 5, 6, 6, 1, 7, 0, 5, 4,\n",
       "       5, 7, 7, 9, 8, 4, 8, 7, 4, 8, 6, 4, 1, 7, 2, 2, 8, 0, 1, 7, 7, 5,\n",
       "       0, 7, 3, 9, 6, 4, 9, 7, 2, 8, 4, 2, 7, 3, 7, 1, 6, 2, 6, 8, 6, 8,\n",
       "       0, 0, 6, 6, 6, 1, 1, 8, 4, 1, 3, 7, 6, 0, 5, 6, 2, 4, 4, 9, 5, 8,\n",
       "       8, 3, 2, 7, 7, 7, 7, 8, 4, 4, 7, 0, 6, 4, 1, 4, 9, 9, 0, 3, 8, 4,\n",
       "       1, 8, 2, 4, 1, 3, 2, 5, 2, 9, 7, 3, 1, 8, 6, 8, 2, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(acc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
